{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà Baseline Models\n",
    "- Persistence baseline (next week = last week)\n",
    "- XGBoost with engineered features\n",
    "- Evaluate MAE / RMSE / MAPE / Peak MAE\n",
    "- Save models, metrics, and training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, json, time, numpy as np, pandas as pd, joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_DIR  = '/content/drive/MyDrive/Electricity_Load_Forecast'\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'models')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "config         = joblib.load(os.path.join(MODEL_DIR, 'config.pkl'))\n",
    "target_scaler  = joblib.load(os.path.join(MODEL_DIR, 'target_scaler.pkl'))\n",
    "\n",
    "X_train_w = np.load(os.path.join(MODEL_DIR, 'X_train_w.npy'))\n",
    "y_train_w = np.load(os.path.join(MODEL_DIR, 'y_train_w.npy'))\n",
    "X_val_w   = np.load(os.path.join(MODEL_DIR, 'X_val_w.npy'))\n",
    "y_val_w   = np.load(os.path.join(MODEL_DIR, 'y_val_w.npy'))\n",
    "X_test_w  = np.load(os.path.join(MODEL_DIR, 'X_test_w.npy'))\n",
    "y_test_w  = np.load(os.path.join(MODEL_DIR, 'y_test_w.npy'))\n",
    "\n",
    "LOAD_IDX   = config['load_col_idx']\n",
    "INPUT_LEN  = config['INPUT_LEN']\n",
    "OUTPUT_LEN = config['OUTPUT_LEN']\n",
    "\n",
    "print(f\"Train: {X_train_w.shape}, Val: {X_val_w.shape}, Test: {X_test_w.shape}\")\n",
    "print(f\"Load column index: {LOAD_IDX}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def inverse_scale(y_scaled):\n",
    "    \"\"\"Inverse-transform scaled load values back to MW.\"\"\"\n",
    "    return target_scaler.inverse_transform(y_scaled.reshape(-1, 1)).reshape(y_scaled.shape)\n",
    "\n",
    "def compute_metrics(y_true, y_pred, label=\"\"):\n",
    "    \"\"\"Compute MAE, RMSE, MAPE, Peak MAE on original-scale values.\"\"\"\n",
    "    y_t = inverse_scale(y_true)\n",
    "    y_p = inverse_scale(y_pred)\n",
    "    mae  = mean_absolute_error(y_t.flatten(), y_p.flatten())\n",
    "    rmse = np.sqrt(mean_squared_error(y_t.flatten(), y_p.flatten()))\n",
    "    mask = y_t.flatten() != 0\n",
    "    mape = np.mean(np.abs((y_t.flatten()[mask] - y_p.flatten()[mask]) / y_t.flatten()[mask])) * 100\n",
    "    # Peak MAE: error at peak load hour in each window\n",
    "    peak_errors = [np.abs(y_t[i, np.argmax(y_t[i])] - y_p[i, np.argmax(y_t[i])]) for i in range(len(y_t))]\n",
    "    peak_mae = np.mean(peak_errors)\n",
    "    metrics = {'MAE': round(mae, 2), 'RMSE': round(rmse, 2),\n",
    "               'MAPE': round(mape, 2), 'Peak_MAE': round(peak_mae, 2)}\n",
    "    if label:\n",
    "        print(f\"\\n{'='*40}\\n{label}\\n{'='*40}\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"  {k:10s}: {v}\")\n",
    "    return metrics"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#  1) PERSISTENCE BASELINE ‚Äî next week = last week\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def persistence_predict(X_windows, load_idx):\n",
    "    \"\"\"Predict next 168h = last 168h of observed load in the input window.\"\"\"\n",
    "    return X_windows[:, :, load_idx]  # (N, 168) ‚Äî the load from input window\n",
    "\n",
    "y_pred_persist_val  = persistence_predict(X_val_w, LOAD_IDX)\n",
    "y_pred_persist_test = persistence_predict(X_test_w, LOAD_IDX)\n",
    "\n",
    "persist_val  = compute_metrics(y_val_w,  y_pred_persist_val,  \"Persistence ‚Äî Validation\")\n",
    "persist_test = compute_metrics(y_test_w, y_pred_persist_test, \"Persistence ‚Äî Test\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#  2) XGBOOST WITH ENGINEERED FEATURES\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def engineer_features(X_windows, load_idx):\n",
    "    \"\"\"Extract summary statistics from each input window for XGBoost.\"\"\"\n",
    "    feat_list = []\n",
    "    for w in X_windows:\n",
    "        f = []\n",
    "        load = w[:, load_idx]\n",
    "        # Load statistics (9 features)\n",
    "        f.extend([load.mean(), load.std(), load.min(), load.max(),\n",
    "                  load[-1], load[0], load[-1] - load[0],\n",
    "                  load[-24:].mean(), load[-48:].mean()])\n",
    "        # Other features: mean + last value (2 per column)\n",
    "        for j in range(w.shape[1]):\n",
    "            if j != load_idx:\n",
    "                f.extend([w[:, j].mean(), w[-1, j]])\n",
    "        feat_list.append(f)\n",
    "    return np.array(feat_list, dtype=np.float32)\n",
    "\n",
    "print(\"\\nEngineering XGBoost features...\")\n",
    "t0 = time.time()\n",
    "Xf_train = engineer_features(X_train_w, LOAD_IDX)\n",
    "Xf_val   = engineer_features(X_val_w,   LOAD_IDX)\n",
    "Xf_test  = engineer_features(X_test_w,  LOAD_IDX)\n",
    "print(f\"  Done in {time.time()-t0:.1f}s ‚Äî shape: {Xf_train.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nTraining XGBoost (multi-output, this may take a few minutes)...\")\n",
    "t0 = time.time()\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    tree_method='hist',       # Use 'gpu_hist' if GPU available\n",
    "    random_state=42,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# XGBoost supports multi-output when y has shape (n_samples, n_outputs)\n",
    "xgb_model.fit(\n",
    "    Xf_train, y_train_w,\n",
    "    eval_set=[(Xf_val, y_val_w)],\n",
    "    verbose=50\n",
    ")\n",
    "print(f\"XGBoost trained in {time.time()-t0:.1f}s\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred_xgb_val  = xgb_model.predict(Xf_val)\n",
    "y_pred_xgb_test = xgb_model.predict(Xf_test)\n",
    "\n",
    "xgb_val  = compute_metrics(y_val_w,  y_pred_xgb_val,  \"XGBoost ‚Äî Validation\")\n",
    "xgb_test = compute_metrics(y_test_w, y_pred_xgb_test, \"XGBoost ‚Äî Test\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "evals = xgb_model.evals_result()\n",
    "if evals:\n",
    "    val_key = list(evals.keys())[0]\n",
    "    loss_key = list(evals[val_key].keys())[0]\n",
    "    xgb_loss = evals[val_key][loss_key]\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(xgb_loss, label='XGBoost Val Loss')\n",
    "    plt.xlabel('Boosting Round'); plt.ylabel('Loss'); plt.title('XGBoost Training Curve')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(MODEL_DIR, 'xgb_training_loss.png'), dpi=150)\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "joblib.dump(xgb_model, os.path.join(MODEL_DIR, 'xgb_model.pkl'))\n",
    "\n",
    "baseline_metrics = {\n",
    "    'Persistence': {'val': persist_val, 'test': persist_test},\n",
    "    'XGBoost':     {'val': xgb_val,     'test': xgb_test}\n",
    "}\n",
    "with open(os.path.join(MODEL_DIR, 'baseline_metrics.json'), 'w') as f:\n",
    "    json.dump(baseline_metrics, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Saved: xgb_model.pkl, baseline_metrics.json, xgb_training_loss.png\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"BASELINE COMPARISON (Test Set)\")\n",
    "print(\"=\"*65)\n",
    "print(f\"{'Model':<15} {'MAE':>8} {'RMSE':>8} {'MAPE%':>8} {'PeakMAE':>10}\")\n",
    "print(\"-\"*65)\n",
    "for model_name, m in baseline_metrics.items():\n",
    "    t = m['test']\n",
    "    print(f\"{model_name:<15} {t['MAE']:>8} {t['RMSE']:>8} {t['MAPE']:>8} {t['Peak_MAE']:>10}\")\n",
    "print(\"=\"*65)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    sample_idx = idx * (len(y_test_w) // 4)\n",
    "    y_true_inv = inverse_scale(y_test_w[sample_idx:sample_idx+1])[0]\n",
    "    y_pers_inv = inverse_scale(y_pred_persist_test[sample_idx:sample_idx+1])[0]\n",
    "    y_xgb_inv  = inverse_scale(y_pred_xgb_test[sample_idx:sample_idx+1])[0]\n",
    "    ax.plot(y_true_inv, 'k-', lw=2, label='Actual')\n",
    "    ax.plot(y_pers_inv, 'r--', alpha=0.7, label='Persistence')\n",
    "    ax.plot(y_xgb_inv,  'b--', alpha=0.7, label='XGBoost')\n",
    "    ax.set_title(f'Test Sample #{sample_idx}')\n",
    "    ax.set_xlabel('Hour'); ax.set_ylabel('Load (MW)')\n",
    "    ax.legend(); ax.grid(True, alpha=0.3)\n",
    "plt.suptitle('Baseline Predictions vs Actual (Test Set)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'baseline_predictions.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Done! Proceed to deep_learning_model notebook.\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
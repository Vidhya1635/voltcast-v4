{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Scaling & Sequences\n",
    "- Load preprocessed data\n",
    "- Chronological split (Train 2018-2022 / Val 2023 / Test 2024-2025)\n",
    "- Fit scalers on train only, transform val & test\n",
    "- Create sliding windows (168h input â†’ 168h output)\n",
    "- Save everything to models/\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, json, numpy as np, pandas as pd, joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "# ====== CONFIGURATION â€” UPDATE THIS PATH ======\n",
    "BASE_DIR = '/content/drive/MyDrive/Electricity_Load_Forecast'\n",
    "DATA_FILE = 'preprocessed_load_data.csv'\n",
    "# ================================================\n",
    "\n",
    "DATA_PATH = os.path.join(BASE_DIR, 'data', DATA_FILE)\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'models')\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "INPUT_LEN  = 168   # 1 week lookback\n",
    "OUTPUT_LEN = 168   # 1 week forecast\n",
    "BOUNDARY_GAP = 168 # gap at start of val/test to avoid cross-split leakage"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df = df.sort_values('Timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Range: {df['Timestamp'].min()} â†’ {df['Timestamp'].max()}\")\n",
    "print(f\"Missing: {df.isnull().sum().sum()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TARGET_COL = 'load'\n",
    "TIMESTAMP_COL = 'Timestamp'\n",
    "SIN_COS_COLS = ['Hour_sin','Hour_cos','Day_sin','Day_cos','Month_sin','Month_cos']\n",
    "\n",
    "# Numerical columns to scale (everything except timestamp, target, sin/cos)\n",
    "NUMERICAL_COLS = [c for c in df.columns if c not in [TIMESTAMP_COL, TARGET_COL] + SIN_COS_COLS]\n",
    "# All feature columns for model input (numerical + sin/cos + target-as-input)\n",
    "FEATURE_COLS = NUMERICAL_COLS + SIN_COS_COLS + [TARGET_COL]\n",
    "\n",
    "print(f\"Numerical (to scale): {len(NUMERICAL_COLS)}\")\n",
    "print(f\"Sin/Cos (no scaling):  {len(SIN_COS_COLS)}\")\n",
    "print(f\"Target (scale separately): {TARGET_COL}\")\n",
    "print(f\"Total input features: {len(FEATURE_COLS)}  â†’ model input (168, {len(FEATURE_COLS)})\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_train = df[df['Timestamp'].dt.year.isin([2018,2019,2020,2021,2022])].copy().reset_index(drop=True)\n",
    "df_val   = df[df['Timestamp'].dt.year == 2023].copy().reset_index(drop=True)\n",
    "df_test  = df[df['Timestamp'].dt.year.isin([2024,2025])].copy().reset_index(drop=True)\n",
    "\n",
    "for name, split in [('Train', df_train), ('Val', df_val), ('Test', df_test)]:\n",
    "    print(f\"{name:5s}: {len(split):,} rows | {split['Timestamp'].min()} â†’ {split['Timestamp'].max()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_scaler = StandardScaler()\n",
    "target_scaler  = StandardScaler()\n",
    "\n",
    "df_train[NUMERICAL_COLS] = feature_scaler.fit_transform(df_train[NUMERICAL_COLS])\n",
    "df_train[[TARGET_COL]]   = target_scaler.fit_transform(df_train[[TARGET_COL]])\n",
    "\n",
    "# Save scalers\n",
    "joblib.dump(feature_scaler, os.path.join(MODEL_DIR, 'feature_scaler.pkl'))\n",
    "joblib.dump(target_scaler,  os.path.join(MODEL_DIR, 'target_scaler.pkl'))\n",
    "print(\"âœ… Scalers fitted on train and saved to models/\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_val[NUMERICAL_COLS]  = feature_scaler.transform(df_val[NUMERICAL_COLS])\n",
    "df_val[[TARGET_COL]]    = target_scaler.transform(df_val[[TARGET_COL]])\n",
    "\n",
    "df_test[NUMERICAL_COLS] = feature_scaler.transform(df_test[NUMERICAL_COLS])\n",
    "df_test[[TARGET_COL]]   = target_scaler.transform(df_test[[TARGET_COL]])\n",
    "print(\"âœ… Val & Test transformed (using train-fitted scalers)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_windows(features, target, input_len, output_len, start_offset=0):\n",
    "    \"\"\"\n",
    "    Sliding windows: X = features[i:i+input_len], y = target[i+input_len:i+input_len+output_len]\n",
    "    start_offset: skip this many timesteps from the beginning (for boundary gap)\n",
    "    \"\"\"\n",
    "    X_windows, y_windows = [], []\n",
    "    end = len(features) - input_len - output_len + 1\n",
    "    for i in range(start_offset, end):\n",
    "        X_windows.append(features[i : i + input_len])\n",
    "        y_windows.append(target[i + input_len : i + input_len + output_len])\n",
    "    return np.array(X_windows, dtype=np.float32), np.array(y_windows, dtype=np.float32)\n",
    "\n",
    "def split_to_arrays(df_split):\n",
    "    X = df_split[FEATURE_COLS].values.astype(np.float32)\n",
    "    y = df_split[TARGET_COL].values.astype(np.float32)\n",
    "    return X, y\n",
    "\n",
    "X_tr, y_tr = split_to_arrays(df_train)\n",
    "X_va, y_va = split_to_arrays(df_val)\n",
    "X_te, y_te = split_to_arrays(df_test)\n",
    "\n",
    "# Train: no gap needed (first split)\n",
    "X_train_w, y_train_w = create_windows(X_tr, y_tr, INPUT_LEN, OUTPUT_LEN, start_offset=0)\n",
    "# Val/Test: 168h gap from split boundary\n",
    "X_val_w,   y_val_w   = create_windows(X_va, y_va, INPUT_LEN, OUTPUT_LEN, start_offset=BOUNDARY_GAP)\n",
    "X_test_w,  y_test_w  = create_windows(X_te, y_te, INPUT_LEN, OUTPUT_LEN, start_offset=BOUNDARY_GAP)\n",
    "\n",
    "print(f\"Train windows: X={X_train_w.shape}, y={y_train_w.shape}\")\n",
    "print(f\"Val   windows: X={X_val_w.shape},   y={y_val_w.shape}\")\n",
    "print(f\"Test  windows: X={X_test_w.shape},  y={y_test_w.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for name, arr in [('X_train_w', X_train_w), ('y_train_w', y_train_w),\n",
    "                  ('X_val_w', X_val_w), ('y_val_w', y_val_w),\n",
    "                  ('X_test_w', X_test_w), ('y_test_w', y_test_w)]:\n",
    "    np.save(os.path.join(MODEL_DIR, f'{name}.npy'), arr)\n",
    "\n",
    "config = {\n",
    "    'FEATURE_COLS': FEATURE_COLS,\n",
    "    'TARGET_COL': TARGET_COL,\n",
    "    'NUMERICAL_COLS': NUMERICAL_COLS,\n",
    "    'SIN_COS_COLS': SIN_COS_COLS,\n",
    "    'INPUT_LEN': INPUT_LEN,\n",
    "    'OUTPUT_LEN': OUTPUT_LEN,\n",
    "    'N_FEATURES': len(FEATURE_COLS),\n",
    "    'load_col_idx': FEATURE_COLS.index(TARGET_COL),\n",
    "}\n",
    "joblib.dump(config, os.path.join(MODEL_DIR, 'config.pkl'))\n",
    "print(\"âœ… All windows and config saved to models/\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "for ax, name, yw in zip(axes, ['Train','Val','Test'], [y_train_w, y_val_w, y_test_w]):\n",
    "    # Plot first 5 windows (targets)\n",
    "    for j in range(min(5, len(yw))):\n",
    "        ax.plot(yw[j], alpha=0.5)\n",
    "    ax.set_title(f'{name} â€” sample target windows (scaled)')\n",
    "    ax.set_xlabel('Horizon (hours)')\n",
    "    ax.set_ylabel('Load (scaled)')\n",
    "plt.tight_layout(); plt.savefig(os.path.join(MODEL_DIR, 'window_samples.png'), dpi=150); plt.show()\n",
    "print(\"âœ… Done! Proceed to baseline_model notebook.\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}